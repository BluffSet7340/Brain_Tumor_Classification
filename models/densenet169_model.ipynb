{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import AlexNet_Weights\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "from torchvision.models import densenet169, DenseNet169_Weights\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3 channels\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard normalization for 3 channels\n",
    "])\n",
    "\n",
    "# Load dataset using ImageFolder\n",
    "dataset_root = \"../dataset/Augmented/\"  \n",
    "dataset = ImageFolder(root=dataset_root, transform=transform)\n",
    "\n",
    "# First split: train (70%) and temp (30%)\n",
    "train_indices, temp_indices = train_test_split(\n",
    "    range(len(dataset)),\n",
    "    test_size=0.3,\n",
    "    stratify=dataset.targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: temp into validation (10% of total) and test (20% of total)\n",
    "val_indices, test_indices = train_test_split(\n",
    "    temp_indices,\n",
    "    test_size=2/3,  # 2/3 of 30% is 20% of the total dataset\n",
    "    stratify=[dataset.targets[i] for i in temp_indices],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Print class distribution in the full dataset\n",
    "print(\"Full dataset class distribution:\", Counter(dataset.targets))\n",
    "\n",
    "# Print class distribution in the training set\n",
    "train_labels = [dataset.targets[i] for i in train_indices]\n",
    "print(\"Training set class distribution:\", Counter(train_labels))\n",
    "\n",
    "# Print class distribution in the validation set\n",
    "val_labels = [dataset.targets[i] for i in val_indices]\n",
    "print(\"Validation set class distribution:\", Counter(val_labels))\n",
    "\n",
    "# Print class distribution in the test set\n",
    "test_labels = [dataset.targets[i] for i in test_indices]\n",
    "print(\"Test set class distribution:\", Counter(test_labels))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Define model (DenseNet-169)\n",
    "class DenseNet169Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(DenseNet169Classifier, self).__init__()\n",
    "        # Load DenseNet-169 with pretrained weights\n",
    "        self.model = densenet169(weights=DenseNet169_Weights.IMAGENET1K_V1)\n",
    "        # Modify the classifier to match the number of output classes\n",
    "        self.model.classifier = nn.Linear(self.model.classifier.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Model setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = DenseNet169Classifier(num_classes=4).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop with validation\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    # Training phase\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = correct / total * 100\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = correct / total * 100\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_loss, correct, total = 0.0, 0, 0\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "all_probabilities = []\n",
    "\n",
    "# Reverse the class_to_idx mapping to get idx_to_class\n",
    "idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)  # Get probabilities\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Collect all labels, predictions, and probabilities for metrics\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = correct / total * 100\n",
    "\n",
    "# Convert numeric predictions and labels to class names\n",
    "all_labels_names = [idx_to_class[label] for label in all_labels]\n",
    "all_predictions_names = [idx_to_class[pred] for pred in all_predictions]\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "conf_matrix_df = pd.DataFrame(\n",
    "    conf_matrix,\n",
    "    index=[f\"True: {label}\" for label in dataset.classes],  # True labels\n",
    "    columns=[f\"Pred: {label}\" for label in dataset.classes]  # Predicted labels\n",
    ")\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_predictions, target_names=dataset.classes))\n",
    "\n",
    "# Calculate ROC and AUC for each class\n",
    "print(\"\\nROC and AUC Metrics:\")\n",
    "for i, class_name in enumerate(dataset.classes):\n",
    "    true_binary = [1 if label == i else 0 for label in all_labels]  # Binary labels for the current class\n",
    "    probabilities = [prob[i] for prob in all_probabilities]  # Probabilities for the current class\n",
    "\n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(true_binary, probabilities)\n",
    "    auc_score = roc_auc_score(true_binary, probabilities)\n",
    "    print(f\"Class '{class_name}': AUC = {auc_score:.4f}\")\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {auc_score:.4f})\")\n",
    "\n",
    "# Plot settings\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n",
    "plt.title(\"ROC Curves\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
